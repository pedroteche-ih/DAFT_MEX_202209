{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Transformers\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/pedroteche-ih/DAFT_MEX_202209/main/data/tb_hotel_traintest.csv'\n",
    "tb_hotel = pd.read_csv(url, parse_dates = ['arrival_date', 'reservation_status_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 113409 entries, 0 to 113408\n",
      "Data columns (total 29 columns):\n",
      " #   Column                          Non-Null Count   Dtype         \n",
      "---  ------                          --------------   -----         \n",
      " 0   hotel                           113409 non-null  object        \n",
      " 1   is_cancelled                    113409 non-null  int64         \n",
      " 2   lead_time                       113409 non-null  int64         \n",
      " 3   stays_in_weekend_nights         113409 non-null  int64         \n",
      " 4   stays_in_week_nights            113409 non-null  int64         \n",
      " 5   adults                          113409 non-null  int64         \n",
      " 6   children                        113406 non-null  float64       \n",
      " 7   babies                          113409 non-null  int64         \n",
      " 8   meal                            113409 non-null  object        \n",
      " 9   country                         112951 non-null  object        \n",
      " 10  market_segment                  113409 non-null  object        \n",
      " 11  distribution_channel            113409 non-null  object        \n",
      " 12  is_repeated_guest               113409 non-null  int64         \n",
      " 13  previous_cancellations          113409 non-null  int64         \n",
      " 14  previous_bookings_not_canceled  113409 non-null  int64         \n",
      " 15  reserved_room_type              113409 non-null  object        \n",
      " 16  assigned_room_type              113409 non-null  object        \n",
      " 17  booking_changes                 113409 non-null  int64         \n",
      " 18  deposit_type                    113409 non-null  object        \n",
      " 19  agent                           97918 non-null   float64       \n",
      " 20  company                         6437 non-null    float64       \n",
      " 21  days_in_waiting_list            113409 non-null  int64         \n",
      " 22  customer_type                   113409 non-null  object        \n",
      " 23  adr                             113409 non-null  float64       \n",
      " 24  required_car_parking_spaces     113409 non-null  int64         \n",
      " 25  total_of_special_requests       113409 non-null  int64         \n",
      " 26  reservation_status_date         113409 non-null  datetime64[ns]\n",
      " 27  arrival_date                    113409 non-null  datetime64[ns]\n",
      " 28  id_booking                      113409 non-null  int64         \n",
      "dtypes: datetime64[ns](2), float64(4), int64(14), object(9)\n",
      "memory usage: 25.1+ MB\n"
     ]
    }
   ],
   "source": [
    "tb_hotel.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building & Evaluating Models in SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_hotel_data(hotel_data):\n",
    "    hotel_data['children'] = hotel_data['children'].fillna(0)\n",
    "    hotel_data['country'] = hotel_data['country'].fillna('Unknown')\n",
    "    hotel_data['is_company'] = np.where(hotel_data['company'].isna(), 0, 1)\n",
    "    hotel_data['is_agent'] = np.where(hotel_data['agent'].isna(), 0, 1)\n",
    "    hotel_data = hotel_data.drop(['company', 'agent', 'id_booking', 'reservation_status_date'], axis = 1).dropna()\n",
    "\n",
    "    return hotel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_hotel_clean = clean_hotel_data(tb_hotel)\n",
    "X = tb_hotel_clean.drop('is_cancelled', axis = 1)\n",
    "y = tb_hotel_clean['is_cancelled']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_num = X_train.select_dtypes(include = 'number')\n",
    "X_test_num = X_test[X_train_num.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_trans = PowerTransformer()\n",
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "dt_fit = DecisionTreeClassifier()\n",
    "log_fit = LogisticRegression()\n",
    "\n",
    "X_train_num_t = power_trans.fit_transform(X_train_num)\n",
    "X_train_num_s = scaler.fit_transform(X_train_num_t)\n",
    "X_train_num_p = scaler.fit_transform(X_train_num_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_fit.fit(X_train_num_p, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'max_depth': [1, 5, 10, 15, 20],\n",
       "                         'min_samples_leaf': [1, 13, 25, 37, 50],\n",
       "                         'min_samples_split': [2, 26, 51, 75, 100]})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para_grid = {\n",
    "    'max_depth' : [int(x) for x in np.linspace(1, 150, 5)],\n",
    "    'min_samples_split' : [int(x) for x in np.linspace(2, 100, 5)],\n",
    "    'min_samples_leaf' : [int(x) for x in np.linspace(1, 50, 5)],\n",
    "    }\n",
    "\n",
    "cv_fit = GridSearchCV(dt_fit, param_grid= para_grid)\n",
    "cv_fit.fit(X_train_num_p, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_num_t = power_trans.transform(X_test_num)\n",
    "X_test_num_s = scaler.transform(X_test_num_t)\n",
    "X_test_num_p = scaler.transform(X_test_num_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_log = log_fit.predict(X_test_num_p)\n",
    "y_pred_dt = cv_fit.predict(X_test_num_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy\n",
    "\n",
    "*Out of all predicitions, what % were correct?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_acc = np.round(accuracy_score(y_test, y_pred_log), 2)\n",
    "dt_acc = np.round(accuracy_score(y_test, y_pred_dt), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.75\n",
      "D.T. Regression Accuracy: 0.79\n"
     ]
    }
   ],
   "source": [
    "print(f'Logistic Regression Accuracy: {log_acc}')\n",
    "print(f'D.T. Regression Accuracy: {dt_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision\n",
    "\n",
    "*Out of all cancellation predicitions, what % were correct?*\n",
    "\n",
    "**Precision is the ratio between True Positives (correct positive predictions) and True/False Positives (all positive predictions).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Precision: 0.71\n",
      "D.T. Regression Precision: 0.76\n"
     ]
    }
   ],
   "source": [
    "log_prc = np.round(precision_score(y_test, y_pred_log), 2)\n",
    "dt_prc = np.round(precision_score(y_test, y_pred_dt), 2)\n",
    "\n",
    "print(f'Logistic Regression Precision: {log_prc}')\n",
    "print(f'D.T. Regression Precision: {dt_prc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall\n",
    "\n",
    "*Out of all real cancellations, what % were correctly predicted?*\n",
    "\n",
    "**Recall is the ration between True Positives (correct positive predictions) and Real Positives (observed positive outcomes).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Recall: 0.57\n",
      "D.T. Regression Recall: 0.65\n"
     ]
    }
   ],
   "source": [
    "log_rec = np.round(recall_score(y_test, y_pred_log), 2)\n",
    "dt_rec = np.round(recall_score(y_test, y_pred_dt), 2)\n",
    "\n",
    "print(f'Logistic Regression Recall: {log_rec}')\n",
    "print(f'D.T. Regression Recall: {dt_rec}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### f1-Score\n",
    "\n",
    "**The *harmonic mean* between precision and recall:**\n",
    "\n",
    "$$f_1 = 2 \\frac{precision * recall}{precision + recall}$$\n",
    "\n",
    "A **f1-score = 1** means our model has perfect precision (all its cancellation predictions were cancellations) and perfect recall (all observed cancellations were predicted correctly). The lower the f1-score the farther we are from a good model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Precision: 0.63\n",
      "D.T. Regression Precision: 0.7\n"
     ]
    }
   ],
   "source": [
    "log_f1 = np.round(f1_score(y_test, y_pred_log), 2)\n",
    "dt_f1 = np.round(f1_score(y_test, y_pred_dt), 2)\n",
    "\n",
    "print(f'Logistic Regression F1: {log_f1}')\n",
    "print(f'D.T. Regression F1: {dt_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilizing precision, recall and F1 for model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    prc = np.round(precision_score(y_true, y_pred), 2)\n",
    "    f1 = np.round(f1_score(y_true, y_pred), 2)\n",
    "    rec = np.round(recall_score(y_true, y_pred), 2)\n",
    "\n",
    "    print(f'Logistic Regression F1: {f1}')\n",
    "    print(f'Logistic Regression Precision: {prc}')\n",
    "    print(f'Logistic Regression Recall: {rec}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1: 0.63\n",
      "D.T. Regression F1: 0.7\n",
      "Logistic Regression Precision: 0.71\n",
      "D.T. Regression Precision: 0.76\n",
      "Logistic Regression Recall: 0.57\n",
      "D.T. Regression Recall: 0.65\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(y_test, y_pred_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_trans = PowerTransformer()\n",
    "scaler = StandardScaler()\n",
    "pca = PCA()\n",
    "dt_fit = DecisionTreeClassifier()\n",
    "blocks = [('TRANS', power_trans), ('SCALE', scaler), ('PCA', pca), ('MODEL', dt_fit)]\n",
    "\n",
    "pipeline = Pipeline(blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=Pipeline(steps=[('TRANS', PowerTransformer()),\n",
       "                                             ('SCALE', StandardScaler()),\n",
       "                                             ('PCA', PCA()),\n",
       "                                             ('MODEL',\n",
       "                                              DecisionTreeClassifier())]),\n",
       "                   param_distributions={'MODEL__max_depth': [1, 4, 7, 10, 13,\n",
       "                                                             16, 19, 22, 25, 28,\n",
       "                                                             31, 34, 37, 40, 43,\n",
       "                                                             46, 49, 52, 55, 58,\n",
       "                                                             61, 64, 67, 70, 73,\n",
       "                                                             77, 80, 83, 86, 89, ...],\n",
       "                                        'MODEL__min_samples_leaf': [1, 2, 3, 4,\n",
       "                                                                    5, 6, 7, 8,\n",
       "                                                                    9, 10, 11,\n",
       "                                                                    12, 13, 14,\n",
       "                                                                    15, 16, 17,\n",
       "                                                                    18, 19, 20,\n",
       "                                                                    21, 22, 23,\n",
       "                                                                    24, 25, 26,\n",
       "                                                                    27, 28, 29,\n",
       "                                                                    30, ...],\n",
       "                                        'MODEL__min_samples_split': [2, 4, 6, 8,\n",
       "                                                                     10, 12, 14,\n",
       "                                                                     16, 18, 20,\n",
       "                                                                     22, 24, 26,\n",
       "                                                                     28, 30, 32,\n",
       "                                                                     34, 36, 38,\n",
       "                                                                     40, 42, 44,\n",
       "                                                                     46, 48, 50,\n",
       "                                                                     52, 54, 56,\n",
       "                                                                     58, 60, ...],\n",
       "                                        'PCA__n_components': range(1, 16)},\n",
       "                   scoring='f1')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_vars = X_train_num.shape[1]\n",
    "\n",
    "para_grid = {\n",
    "    'PCA__n_components' : range(1, num_vars), \n",
    "    'MODEL__max_depth' : [int(x) for x in np.linspace(1, 150, 50)],\n",
    "    'MODEL__min_samples_split' : [int(x) for x in np.linspace(2, 100, 50)],\n",
    "    'MODEL__min_samples_leaf' : [int(x) for x in np.linspace(1, 50, 50)],\n",
    "}\n",
    "\n",
    "cv_fit = RandomizedSearchCV(pipeline, param_distributions= para_grid, n_iter = 10, scoring = 'f1')\n",
    "cv_fit.fit(X_train_num, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression F1: 0.63\n",
      "Logistic Regression Precision: 0.71\n",
      "Logistic Regression Recall: 0.57\n"
     ]
    }
   ],
   "source": [
    "y_pred_pipeline = cv_fit.predict(X_test_num)\n",
    "evaluate_model(y_test, y_pred_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('TRANS', PowerTransformer()), ('SCALE', StandardScaler()),\n",
       "                ('PCA', PCA(n_components=7)),\n",
       "                ('MODEL',\n",
       "                 DecisionTreeClassifier(max_depth=73, min_samples_leaf=22,\n",
       "                                        min_samples_split=14))])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_fit.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/pedroteche/Documents/GitHub/DAFT_MEX_202209/Model Evaluation - Classification Problems.ipynb Cell 34\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedroteche/Documents/GitHub/DAFT_MEX_202209/Model%20Evaluation%20-%20Classification%20Problems.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m para_grid \u001b[39m=\u001b[39m {\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedroteche/Documents/GitHub/DAFT_MEX_202209/Model%20Evaluation%20-%20Classification%20Problems.ipynb#X66sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mPCA__n_components\u001b[39m\u001b[39m'\u001b[39m : \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m, num_vars), \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedroteche/Documents/GitHub/DAFT_MEX_202209/Model%20Evaluation%20-%20Classification%20Problems.ipynb#X66sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMODEL__max_depth\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39mint\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mlinspace(\u001b[39m63\u001b[39m, \u001b[39m83\u001b[39m, \u001b[39m5\u001b[39m)],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedroteche/Documents/GitHub/DAFT_MEX_202209/Model%20Evaluation%20-%20Classification%20Problems.ipynb#X66sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMODEL__min_samples_split\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39mint\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mlinspace(\u001b[39m12\u001b[39m, \u001b[39m32\u001b[39m, \u001b[39m5\u001b[39m)],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedroteche/Documents/GitHub/DAFT_MEX_202209/Model%20Evaluation%20-%20Classification%20Problems.ipynb#X66sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mMODEL__min_samples_leaf\u001b[39m\u001b[39m'\u001b[39m : [\u001b[39mint\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mlinspace(\u001b[39m4\u001b[39m, \u001b[39m24\u001b[39m, \u001b[39m5\u001b[39m)],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedroteche/Documents/GitHub/DAFT_MEX_202209/Model%20Evaluation%20-%20Classification%20Problems.ipynb#X66sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m }\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedroteche/Documents/GitHub/DAFT_MEX_202209/Model%20Evaluation%20-%20Classification%20Problems.ipynb#X66sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m cv_fit \u001b[39m=\u001b[39m GridSearchCV(pipeline, param_grid\u001b[39m=\u001b[39m para_grid, scoring \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mf1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pedroteche/Documents/GitHub/DAFT_MEX_202209/Model%20Evaluation%20-%20Classification%20Problems.ipynb#X66sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m cv_fit\u001b[39m.\u001b[39;49mfit(X_train_num, y_train)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m    893\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1392\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1391\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1392\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    839\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m         clone(base_estimator),\n\u001b[1;32m    841\u001b[0m         X,\n\u001b[1;32m    842\u001b[0m         y,\n\u001b[1;32m    843\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    844\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    845\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    846\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    847\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    848\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    849\u001b[0m     )\n\u001b[1;32m    850\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    851\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[1;32m    852\u001b[0m     )\n\u001b[1;32m    853\u001b[0m )\n\u001b[1;32m    855\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    682\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/pipeline.py:394\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    393\u001b[0m         fit_params_last_step \u001b[39m=\u001b[39m fit_params_steps[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]]\n\u001b[0;32m--> 394\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_final_estimator\u001b[39m.\u001b[39;49mfit(Xt, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_last_step)\n\u001b[1;32m    396\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m    900\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    901\u001b[0m ):\n\u001b[1;32m    902\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[1;32m    904\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    938\u001b[0m         X,\n\u001b[1;32m    939\u001b[0m         y,\n\u001b[1;32m    940\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    941\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    942\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:420\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    411\u001b[0m         splitter,\n\u001b[1;32m    412\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    418\u001b[0m     )\n\u001b[0;32m--> 420\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    423\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "para_grid = {\n",
    "    'PCA__n_components' : range(5, num_vars), \n",
    "    'MODEL__max_depth' : [int(x) for x in np.linspace(63, 83, 5)],\n",
    "    'MODEL__min_samples_split' : [int(x) for x in np.linspace(12, 32, 5)],\n",
    "    'MODEL__min_samples_leaf' : [int(x) for x in np.linspace(4, 24, 5)],\n",
    "}\n",
    "\n",
    "cv_fit = GridSearchCV(pipeline, param_grid= para_grid, scoring = 'f1')\n",
    "cv_fit.fit(X_train_num, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_pipeline = cv_fit.predict(X_test_num)\n",
    "evaluate_model(y_test, y_pred_log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "014f4a4a5af8f0104b12c029e500f4146d6d785e8cf714d2a35b7a9514230cd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
